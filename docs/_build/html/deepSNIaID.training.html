
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>deepSNIaID.training &#8212; deepSNIaID 0.1.dev0 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="deepSNIaID.utils" href="deepSNIaID.utils.html" />
    <link rel="prev" title="deepSNIaID.architecture" href="deepSNIaID.architecture.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="module-deepSNIaID.training">
<span id="deepsniaid-training"></span><h1>deepSNIaID.training<a class="headerlink" href="#module-deepSNIaID.training" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="deepSNIaID.training.Train">
<em class="property">class </em><code class="sig-prename descclassname">deepSNIaID.training.</code><code class="sig-name descname">Train</code><span class="sig-paren">(</span><em class="sig-param">trainX, trainY, valX, valY, testX=None, testY=None, Ylim=[0.0, 1.0], seed=100, threshold=0.5, regression=True, mcnum=100, kernel=15, filters=16, fc_size=32, drop_rate=0.1, epochs=75, early_stop=[0.0], lr_decay_steps=[45, 60, 70], lr=0.001, batch_size=16, weight_decay=0.0001, verbose=True, wandb=None, save=True, savedir='./'</em><span class="sig-paren">)</span><a class="headerlink" href="#deepSNIaID.training.Train" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>network training</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>train[X,Y]</strong><span class="classifier">np.ndarray</span></dt><dd><p>training [inputs,outputs]</p>
</dd>
<dt><strong>val[X,Y]</strong><span class="classifier">np.ndarray</span></dt><dd><p>validation [inputs,outputs]</p>
</dd>
<dt><strong>test[X,Y]</strong><span class="classifier">np.ndarray, optional</span></dt><dd><p>testing [inputs,outputs]</p>
</dd>
<dt><strong>Ylim</strong><span class="classifier">tuple, list, or other iterable of length 2, optional</span></dt><dd><p>lower and upper limits for for utils.LinearScaler on outputs (Y)</p>
</dd>
<dt><strong>seed</strong><span class="classifier">int, optional</span></dt><dd><p>seed for random number generator</p>
</dd>
<dt><strong>threshold</strong><span class="classifier">float, optional</span></dt><dd><p>minimum threshold for ‘in’ classification by Domain model</p>
</dd>
<dt><strong>regression</strong><span class="classifier">bool, optional</span></dt><dd><p>toggle for regression (determines scalers used)</p>
</dd>
<dt><strong>mcnum</strong><span class="classifier">int, optional</span></dt><dd><p>number of stochastic forward passes to perform</p>
</dd>
<dt><strong>kernel</strong><span class="classifier">odd int, optional</span></dt><dd><p>convolutional kernel size</p>
</dd>
<dt><strong>filters</strong><span class="classifier">int, optional</span></dt><dd><p>number of filters in first convolution layer</p>
</dd>
<dt><strong>fc_size</strong><span class="classifier">int, optional</span></dt><dd><p>number of neurons in fully connected layer</p>
</dd>
<dt><strong>drop_rate</strong><span class="classifier">float, optional</span></dt><dd><p>dropout probability</p>
</dd>
<dt><strong>epochs</strong><span class="classifier">int, optional</span></dt><dd><p>number of training epochs</p>
</dd>
<dt><strong>lr</strong><span class="classifier">float, optional</span></dt><dd><p>initial learning rate</p>
</dd>
<dt><strong>batch_size</strong><span class="classifier">int, optional</span></dt><dd><p>batch size for training</p>
</dd>
<dt><strong>weight_decay</strong><span class="classifier">float, optional</span></dt><dd><p>weight decay for training</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">bool, optional</span></dt><dd><p>show network summary and status bars</p>
</dd>
<dt><strong>save</strong><span class="classifier">bool, optional</span></dt><dd><p>flag for saving training history and trained model</p>
</dd>
<dt><strong>savedir</strong><span class="classifier">str, optional</span></dt><dd><p>directory for save files</p>
</dd>
</dl>
</dd>
<dt class="field-even">Other Parameters</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>early_stop</strong><span class="classifier">length-1 array_like, optional</span></dt><dd><p>early stopping threshold on validation RMSE for regression mode</p>
</dd>
<dt><strong>lr_decay_steps</strong><span class="classifier">array_like, optional</span></dt><dd><p>epochs at which to decay learning rate by factor 10</p>
</dd>
<dt><strong>wandb</strong><span class="classifier">wandb instance, optional</span></dt><dd><p>wandb instance for run tracking</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>device</strong><span class="classifier">torch.device</span></dt><dd><p>device type being used (GPU if available, else CPU)</p>
</dd>
<dt><strong>network</strong><span class="classifier">DropoutCNN</span></dt><dd><p>network to train (may be wrapped in DataParallel if on GPU)</p>
</dd>
<dt><strong>Yscaler</strong><span class="classifier">VoidScaler or LinearScaler</span></dt><dd><p>scaler for Y labels</p>
</dd>
<dt><strong>optimizer</strong><span class="classifier">torch optimizer (Adam)</span></dt><dd><p>optimizer for training</p>
</dd>
<dt><strong>scheduler</strong><span class="classifier">VoidLRScheduler or MultiStepLR</span></dt><dd><p>learning rate scheduler</p>
</dd>
<dt><strong>loss</strong><span class="classifier">torch loss</span></dt><dd><p>loss for training</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#deepSNIaID.training.Train.test_epoch" title="deepSNIaID.training.Train.test_epoch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">test_epoch</span></code></a>(self, X, Y[, label])</p></td>
<td><p>perform validation or testing steps for single epoch</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#deepSNIaID.training.Train.train" title="deepSNIaID.training.Train.train"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train</span></code></a>(self)</p></td>
<td><p>train network</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#deepSNIaID.training.Train.train_epoch" title="deepSNIaID.training.Train.train_epoch"><code class="xref py py-obj docutils literal notranslate"><span class="pre">train_epoch</span></code></a>(self)</p></td>
<td><p>perform training steps for single epoch</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepSNIaID.training.Train.train_epoch">
<code class="sig-name descname">train_epoch</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="headerlink" href="#deepSNIaID.training.Train.train_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>perform training steps for single epoch</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><dl class="simple">
<dt>dict</dt><dd><p>training metrics for epoch (loss and lr-current)</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepSNIaID.training.Train.test_epoch">
<code class="sig-name descname">test_epoch</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">X</em>, <em class="sig-param">Y</em>, <em class="sig-param">label=''</em><span class="sig-paren">)</span><a class="headerlink" href="#deepSNIaID.training.Train.test_epoch" title="Permalink to this definition">¶</a></dt>
<dd><p>perform validation or testing steps for single epoch</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">torch.tensor</span></dt><dd><p>inputs</p>
</dd>
<dt><strong>Y</strong><span class="classifier">torch.tensor</span></dt><dd><p>outputs</p>
</dd>
<dt><strong>label</strong><span class="classifier">str, optional</span></dt><dd><p>label to prepend output dict keys with (e.g. ‘val’ or ‘test’)</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>metrics</strong><span class="classifier">dict</span></dt><dd><p>validation or testing metrics for epoch</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deepSNIaID.training.Train.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">self</em><span class="sig-paren">)</span><a class="headerlink" href="#deepSNIaID.training.Train.train" title="Permalink to this definition">¶</a></dt>
<dd><p>train network</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deepSNIaID.training.Sweep">
<em class="property">class </em><code class="sig-prename descclassname">deepSNIaID.training.</code><code class="sig-name descname">Sweep</code><span class="sig-paren">(</span><em class="sig-param">trainX, trainY, valX, valY, entity, project, kernels, filters, fc_sizes, drop_rates, batch_sizes, lrs, weight_decays, seed=100, regression=True, mcnum=100, epochs=75, early_stop=[0.0], Ylim=[0.0, 1.0], sweep_method='random', testX=None, testY=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepSNIaID.training.Sweep" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>sweep (search) through hyperparameters using wandb</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>train[X,Y]</strong><span class="classifier">np.ndarray</span></dt><dd><p>training [inputs,outputs]</p>
</dd>
<dt><strong>val[X,Y]</strong><span class="classifier">np.ndarray</span></dt><dd><p>validation [inputs,outputs]</p>
</dd>
<dt><strong>entity</strong><span class="classifier">str</span></dt><dd><p>wandb entity</p>
</dd>
<dt><strong>project</strong><span class="classifier">str</span></dt><dd><p>wandb project</p>
</dd>
<dt><strong>kernels</strong><span class="classifier">array_like</span></dt><dd><p>convolutional kernel sizes to sweep over</p>
</dd>
<dt><strong>filters</strong><span class="classifier">array_like</span></dt><dd><p>numbers of filters in first convolution layer to sweep over</p>
</dd>
<dt><strong>fc_sizes</strong><span class="classifier">array_like</span></dt><dd><p>numbers of neurons in fully connected layer to sweep over</p>
</dd>
<dt><strong>drop_rates</strong><span class="classifier">array_like</span></dt><dd><p>dropout probabilities to sweep over</p>
</dd>
<dt><strong>batch_sizes</strong><span class="classifier">array_like</span></dt><dd><p>batch sizes to sweep over</p>
</dd>
<dt><strong>lrs</strong><span class="classifier">array_like</span></dt><dd><p>initial learning rates to sweep over</p>
</dd>
<dt><strong>weight_decays</strong><span class="classifier">array_like</span></dt><dd><p>weight decays to sweep over</p>
</dd>
<dt><strong>seed</strong><span class="classifier">int, optional</span></dt><dd><p>seed for random number generator</p>
</dd>
<dt><strong>regression</strong><span class="classifier">bool, optional</span></dt><dd><p>toggle for regression (determines scalers used)</p>
</dd>
<dt><strong>mcnum</strong><span class="classifier">int, optional</span></dt><dd><p>number of stochastic forward passes to perform</p>
</dd>
<dt><strong>epochs</strong><span class="classifier">int, optional</span></dt><dd><p>number of training epochs</p>
</dd>
<dt><strong>Ylim</strong><span class="classifier">tuple, list, or other iterable of length 2, optional</span></dt><dd><p>lower and upper limits for for utils.LinearScaler on outputs (Y)</p>
</dd>
<dt><strong>sweep_method</strong><span class="classifier">str, optional</span></dt><dd><p>method for sweep (‘random’ or ‘grid’)</p>
</dd>
<dt><strong>test[X,Y]</strong><span class="classifier">np.ndarray, optional</span></dt><dd><p>testing [inputs,outputs]</p>
</dd>
</dl>
</dd>
<dt class="field-even">Other Parameters</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>early_stop</strong><span class="classifier">length-1 array_like, optional</span></dt><dd><p>early stopping threshold on validation RMSE for regression mode</p>
</dd>
</dl>
</dd>
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>sweep_config</strong><span class="classifier">dict</span></dt><dd><p>wandb sweep configurations</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#deepSNIaID.training.Sweep.sweep" title="deepSNIaID.training.Sweep.sweep"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sweep</span></code></a>(self[, tags, saveroot])</p></td>
<td><p>run sweep</p></td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="deepSNIaID.training.Sweep.sweep">
<code class="sig-name descname">sweep</code><span class="sig-paren">(</span><em class="sig-param">self</em>, <em class="sig-param">tags=[]</em>, <em class="sig-param">saveroot=None</em><span class="sig-paren">)</span><a class="headerlink" href="#deepSNIaID.training.Sweep.sweep" title="Permalink to this definition">¶</a></dt>
<dd><p>run sweep</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>tags</strong><span class="classifier">list, optional</span></dt><dd><p>list of strings to add as tags to sweep runs</p>
</dd>
<dt><strong>saveroot</strong><span class="classifier">str, optional</span></dt><dd><p>root name to use for saving</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">deepSNIaID</a></h1>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="deepSNIaID.model.html">deepSNIaID</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepSNIaID.preprocessing.html">deepSNIaID.preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepSNIaID.dataset.html">deepSNIaID.dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepSNIaID.architecture.html">deepSNIaID.architecture</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">deepSNIaID.training</a></li>
<li class="toctree-l1"><a class="reference internal" href="deepSNIaID.utils.html">deepSNIaID.utils</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="deepSNIaID.architecture.html" title="previous chapter">deepSNIaID.architecture</a></li>
      <li>Next: <a href="deepSNIaID.utils.html" title="next chapter">deepSNIaID.utils</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Benjamin Stahl.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.3.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/deepSNIaID.training.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>