# imports -- standard
import json
from time import time
import numpy as np
import pandas as pd
import torch
from torch import nn

# imports -- custom
from deepSIP import utils
from deepSIP.architecture import DropoutCNN
from deepSIP.dataset import NumpyXDataset
from deepSIP.preprocessing import EvaluationSpectra
from deepSIP.trained_models import models, model_path

__all__ = ['deepSIP']

class deepSIP:
    '''
    class for deploying trained deepSIP models

    Parameters
    ----------
    spec_len : int, optional
               number of wavelength bins for pre-processed spectra
               (must match what was used in training models)
    seed : int, optional
           seed for random number generator

    Attributes
    ----------
    models : pd.DataFrame
             models, along with metadata and utilities, indexed by purpose
    device : torch.device
             device type being used (GPU if available, else CPU)
    '''

    def __init__(self, spec_len = 1024, seed = 100, drop_rate = None):

        # store needed inputs
        self.seed = seed

        # prefer GPUs
        if torch.cuda.is_available():
            GPU = True
            self.device = torch.device('cuda')
            torch.cuda.empty_cache()
        else:
            GPU = False
            self.device = torch.device('cpu')
            print('No GPU available. Using CPU instead...')

        # load models
        self.models = models.copy()
        Ylim = ['Ymin', 'Ymax']
        for mod, params in self.models.drop(Ylim, axis = 1).iterrows():
            pars = params.to_dict()
            if drop_rate is not None:
                pars['drop_rate'] = drop_rate
            net = DropoutCNN(spec_len, **pars)
            if GPU:
                net = nn.DataParallel(net).to(self.device)
            else:
                net = utils.WrappedModel(net).to(self.device)
            utils.loadnet(net, model_path + '/' + mod + '.pth',
                          'cpu' if not GPU else 'cuda')
            self.models.loc[mod, 'net'] = net

        # load Y scalers
        self.models['Yscaler'] = utils.VoidScaler()
        for mod in self.models.index.drop('Domain'):
            self.models.loc[mod, 'Yscaler'] = \
                            utils.LinearScaler(*self.models.loc[mod, Ylim])


    def predict(self, spectra, threshold = 0.5, mcnum = 75, status = False):
        '''
        make predictions with trained models

        Parameters
        ----------
        spectra : np.ndarray or pd.DataFrame
                  pre-preocessed spectra if np.ndarray else pd.DataFrame with
                  columns of [SN, filename, z] and optionally obsframe as bool
        threshold : float, optional
                    minimum threshold for 'in' classification by Domain model
        mcnum : int, optional
                number of stochastic forward passes to perform
        status : bool, optional
                 show status bars

        Returns
        -------
        pd.DataFrame
            predictions generated by each model
        '''

        # validate and process input
        if type(spectra) not in [np.ndarray, pd.DataFrame]:
            raise TypeError('spectra must be an np.ndarray of preprocessed ' + \
                            'spectra or a pd.DataFrame with columns of ' + \
                            '[SN, filename, z] and optionally obsframe as bool')
        if type(spectra) is pd.DataFrame:
            print('preprocessing input spectra')
            es = EvaluationSpectra(spectra)
            es.process(status = status)
            print('preprocessed spectra written to ' + \
                  es.savefile.replace('.sav', '.npy'))
            spectra = es.X
        ds = NumpyXDataset(spectra)

        # run predictions
        predictions = {}
        for mod in self.models.index:
            if status:
                print('\nstarting {} stochastic passes on {} network'.format(
                       mcnum, mod))
                t1 = time()
            mu, sigma = utils.stochastic_predict(self.models.loc[mod, 'net'],
                                                 ds.X, mcnum = mcnum,
                                                 sigmoid = (True if \
                                                            mod == 'Domain' \
                                                            else False),
                                                 seed = self.seed,
                                                 scaler = \
                                                self.models.loc[mod, 'Yscaler'],
                                                 status = status)
            if mod == 'Domain':
                predictions[mod] = \
                             utils.classify(mu, threshold = threshold)[:, 0]
                predictions['prob_' + mod] = mu[:, 0]
            else:
                if mod == 'Phase':
                    predictions[mod] = mu[:, 0]
                    predictions['e_' + mod] = sigma[:, 0]
                elif mod == 'dm15':
                    predictions[mod] = mu[:, 0]
                    predictions['e_' + mod] = sigma[:, 0]
            if status:
                print('done in {:.3f} s'.format(time() - t1))
        return pd.DataFrame(predictions)
